{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import sktime\n",
    "from sktime.datasets import load_from_tsfile_to_dataframe# Only add the project root to sys.path\n",
    "root_path = os.path.abspath('..')\n",
    "if root_path not in sys.path:\n",
    "    sys.path.insert(0, root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = load_from_tsfile_to_dataframe(\"..//Data//Physio//TEST_X.ts\")\n",
    "pid = np.load(\"..//Data//Physio//TEST_pid.npy\")\n",
    "print(pid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "pid = np.load(\"..//Data//Physio//TEST_pid.npy\")\n",
    "\n",
    "# Convert the fourth column to integers\n",
    "fourth_col_as_int = np.array([int(row[3]) for row in pid])\n",
    "\n",
    "# Sort the pid array based on the fourth column in descending order\n",
    "pid_sorted_desc = pid[fourth_col_as_int.argsort()[::-1]]\n",
    "\n",
    "print(\"Entries sorted in descending order of the fourth part:\")\n",
    "for row in pid_sorted_desc:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each number in the fourth column:\n",
      "11: 16\n",
      "10: 141\n",
      "9: 141\n",
      "8: 141\n",
      "7: 141\n",
      "6: 141\n",
      "5: 141\n",
      "4: 141\n",
      "3: 141\n",
      "2: 141\n",
      "1: 141\n",
      "Sorted PIDs of entries with '11' in the fourth column:\n",
      "P27_R\n",
      "P31_R\n",
      "P37_R\n",
      "P38_R\n",
      "P40_R\n",
      "P41_R\n",
      "P44_R\n",
      "P45_R\n",
      "P46_R\n",
      "P49_R\n",
      "P4_R\n",
      "P50_R\n",
      "P51_R\n",
      "P54_R\n",
      "P55_R\n",
      "P5_R\n",
      "P5_R\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Load the data\n",
    "pid = np.load(\"..//Data//Physio//TRAIN_pid.npy\")\n",
    "\n",
    "# Extract the fourth column and convert it to integers\n",
    "fourth_col_as_int = [int(row[3]) for row in pid]\n",
    "\n",
    "# Count the occurrences of each number\n",
    "count = Counter(fourth_col_as_int)\n",
    "\n",
    "print(\"Count of each number in the fourth column:\")\n",
    "for number, count in sorted(count.items(), reverse=True):\n",
    "    print(f\"{number}: {count}\")\n",
    "    \n",
    "pids_with_11 = [row[0] for row in pid if int(row[3]) == 11]\n",
    "\n",
    "# Sort the collected PIDs\n",
    "sorted_pids_with_11 = sorted(pids_with_11)\n",
    "\n",
    "# Print sorted PIDs\n",
    "print(\"Sorted PIDs of entries with '11' in the fourth column:\")\n",
    "for pid in sorted_pids_with_11:\n",
    "    print(pid)\n",
    "\n",
    "print(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Algorithms.binseg import binseg\n",
    "from Functions.evaluate_binseg import evaluate_binseg\n",
    "from Functions.metrics import f_measure, covering\n",
    "\n",
    "# Load the time series data from the uploaded file\n",
    "ts_file_path = '..//Data//Physio//single_ts.ts'\n",
    "dataset_name = 'single_ts'\n",
    "with open(ts_file_path, 'r') as file:\n",
    "    data = np.array([float(num) for num in file.read().split(',')])\n",
    "    \n",
    "print(data.size)\n",
    "    \n",
    "# Load the change points from the .npy file\n",
    "# Make sure to update the file path to where your .npy file is located\n",
    "npy_file_path = '..//Data//Physio//TEST_pid.npy'\n",
    "change_points_list = np.load(npy_file_path, allow_pickle=True)\n",
    "\n",
    "# Filter out non-numeric strings and convert the rest to integers, excluding the last number\n",
    "true_change_points = [int(point) for point in change_points_list[0][:-1] if point.isdigit()]\n",
    "\n",
    "# Parameters for the Binseg function\n",
    "cost_func = \"rbf\"  # Example cost function\n",
    "n_cps = len(true_change_points)\n",
    "detected_cps = binseg(data, n_cps, cost_func)\n",
    "\n",
    "# Evaluate the detected change points\n",
    "try:\n",
    "    dataset, true_cps, detected_cps, f1_score, covering_score = evaluate_binseg(dataset_name, data, true_change_points, cost_func=cost_func)\n",
    "    print(f\"True Change Points: {true_change_points}\")\n",
    "except TypeError as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(data, label='Time Series Data')\n",
    "for cp in detected_cps:\n",
    "    plt.axvline(x=cp, color='red', linestyle='--', linewidth=1, label='Detected Change Point' if cp == detected_cps[0] else \"\")\n",
    "for cp in true_change_points:\n",
    "    plt.axvline(x=cp, color='green', linestyle='-', linewidth=1, label='True Change Point' if cp == true_change_points[0] else \"\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Time Series Analysis with Detected and True Change Points')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Algorithms.binseg import binseg\n",
    "from Functions.evaluate_binseg import evaluate_binseg\n",
    "from Functions.metrics import f_measure, covering\n",
    "\n",
    "# Load the time series data and change points\n",
    "ts_file_path = '..//Data//Physio//TEST_X.ts'\n",
    "npy_file_path = '..//Data//Physio//TEST_pid.npy'\n",
    "\n",
    "# Function to process a line into sub time series\n",
    "def process_line(line):\n",
    "    sub_series = line.strip().split(':')\n",
    "    sub_series_data = [np.array([float(num) for num in s.split(',')]) for s in sub_series[:-1]]  # Excluding the last empty segment\n",
    "    return sub_series_data\n",
    "\n",
    "# Read the time series data\n",
    "all_sub_time_series = []\n",
    "with open(ts_file_path, 'r') as file:\n",
    "    for _ in range(10):\n",
    "        line = file.readline()\n",
    "        sub_time_series = process_line(line)\n",
    "        all_sub_time_series.append(sub_time_series)\n",
    "\n",
    "# Load the change points for each time series\n",
    "change_points_list = np.load(npy_file_path, allow_pickle=True)[:10]\n",
    "\n",
    "# Iterate over each line's sub time series and their corresponding change points\n",
    "for i, (sub_series_list, change_points) in enumerate(zip(all_sub_time_series, change_points_list)):\n",
    "    for j, data in enumerate(sub_series_list):\n",
    "        series_identifier = f\"Series {i}, Sub-series {j}\"\n",
    "\n",
    "        # Extract the last value from change points if available\n",
    "        last_change_point = change_points[-1] if len(change_points) > 0 else \"None\"\n",
    "\n",
    "        print(f\"{series_identifier} has {len(data)} entries. Last change point: {last_change_point}\")\n",
    "\n",
    "        # Filter out non-numeric strings and convert the rest to integers, excluding the last number\n",
    "        true_change_points = [int(point) for point in change_points[:-1] if isinstance(point, str) and point.isdigit()]\n",
    "        \n",
    "        # Parameters for the Binseg function\n",
    "        cost_func = \"l2\"\n",
    "        n_cps = len(true_change_points)\n",
    "        detected_cps = binseg(data, n_cps, cost_func)\n",
    "\n",
    "        # Evaluate the detected change points\n",
    "        try:\n",
    "            dataset, true_cps, detected_cps, f1_score, covering_score = evaluate_binseg(f\"TEST_X_{i}_{j}\", data, true_change_points, cost_func=cost_func)\n",
    "            print(f\"{series_identifier} - True Change Points: {true_change_points}\")\n",
    "            print(f\"{series_identifier} - Detected Change Points: {detected_cps}\")\n",
    "            print(f\"{series_identifier} - F1 Score: {f1_score}, Covering Score: {covering_score}\")\n",
    "        except TypeError as e:\n",
    "            print(f\"An error occurred for {series_identifier}: {e}\")\n",
    "\n",
    "        # Visualization\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.plot(data, label='Time Series Data')\n",
    "        for cp in detected_cps:\n",
    "            plt.axvline(x=cp, color='red', linestyle='--', linewidth=1, label='Detected Change Point' if cp == detected_cps[0] else \"\")\n",
    "        for cp in true_change_points:\n",
    "            plt.axvline(x=cp, color='green', linestyle='-', linewidth=1, label='True Change Point' if cp == true_change_points[0] else \"\")\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'Time Series Analysis for {series_identifier} with Detected and True Change Points')\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Algorithms.binseg import binseg\n",
    "from Functions.evaluate_binseg import evaluate_binseg\n",
    "from Functions.metrics import f_measure, covering\n",
    "\n",
    "# Load the time series data and change points\n",
    "ts_file_path = '..//Data//Physio//TEST_X.ts'\n",
    "npy_file_path = '..//Data//Physio//TEST_pid.npy'\n",
    "\n",
    "# Function to process a line into sub time series\n",
    "def process_line(line):\n",
    "    sub_series = line.strip().split(':')\n",
    "    sub_series_data = [np.array([float(num) for num in s.split(',')]) for s in sub_series[:-1]]  # Excluding the last empty segment\n",
    "    return sub_series_data\n",
    "\n",
    "# Read the time series data\n",
    "all_sub_time_series = []\n",
    "with open(ts_file_path, 'r') as file:\n",
    "    for _ in range(10):\n",
    "        line = file.readline()\n",
    "        sub_time_series = process_line(line)\n",
    "        all_sub_time_series.append(sub_time_series)\n",
    "\n",
    "# Load the change points for each time series\n",
    "change_points_list = np.load(npy_file_path, allow_pickle=True)[:10]\n",
    "\n",
    "# Find the maximum final number in the .npy file\n",
    "max_final_number = max([points[-1] for points in change_points_list if len(points) > 0])\n",
    "\n",
    "# Print the maximum final number\n",
    "print(f\"The maximum final number in the .npy file is: {max_final_number}\")\n",
    "\n",
    "# Iterate over each line's sub time series and their corresponding change points\n",
    "for i, (sub_series_list, change_points) in enumerate(zip(all_sub_time_series, change_points_list)):\n",
    "    for j, data in enumerate(sub_series_list):\n",
    "        series_identifier = f\"Series {i}, Sub-series {j}\"\n",
    "\n",
    "        # Extract the last value from change points if available\n",
    "        last_change_point = change_points[-1] if len(change_points) > 0 else \"None\"\n",
    "\n",
    "        print(f\"{series_identifier} has {len(data)} entries. Last change point: {last_change_point}\")\n",
    "\n",
    "        # Filter out non-numeric strings and convert the rest to integers, excluding the last number\n",
    "        true_change_points = [int(point) for point in change_points[:-1] if isinstance(point, str) and point.isdigit()]\n",
    "        \n",
    "        # Parameters for the Binseg function\n",
    "        cost_func = \"l2\"\n",
    "        n_cps = len(true_change_points)\n",
    "        detected_cps = binseg(data, n_cps, cost_func)\n",
    "\n",
    "        # Evaluate the detected change points\n",
    "        try:\n",
    "            dataset, true_cps, detected_cps, f1_score, covering_score = evaluate_binseg(f\"TEST_X_{i}_{j}\", data, true_change_points, cost_func=cost_func)\n",
    "            print(f\"{series_identifier} - True Change Points: {true_change_points}\")\n",
    "            print(f\"{series_identifier} - Detected Change Points: {detected_cps}\")\n",
    "            print(f\"{series_identifier} - F1 Score: {f1_score}, Covering Score: {covering_score}\")\n",
    "        except TypeError as e:\n",
    "            print(f\"An error occurred for {series_identifier}: {e}\")\n",
    "\n",
    "        # Visualization\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.plot(data, label='Time Series Data')\n",
    "        for cp in detected_cps:\n",
    "            plt.axvline(x=cp, color='red', linestyle='--', linewidth=1, label='Detected Change Point' if cp == detected_cps[0] else \"\")\n",
    "        for cp in true_change_points:\n",
    "            plt.axvline(x=cp, color='green', linestyle='-', linewidth=1, label='True Change Point' if cp == true_change_points[0] else \"\")\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'Time Series Analysis for {series_identifier} with Detected and True Change Points')\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING NEW FUNCTIONALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Algorithms.binseg import binseg\n",
    "from Functions.evaluate_binseg import evaluate_binseg\n",
    "\n",
    "# Load the time series data and change points\n",
    "ts_file_path = '..//Data//Physio//TEST_X.ts'\n",
    "npy_file_path = '..//Data//Physio//TEST_pid.npy'\n",
    "\n",
    "# Function to process a line into sub time series\n",
    "def process_line(line):\n",
    "    sub_series = line.strip().split(':')\n",
    "    sub_series_data = [np.array([float(num) for num in s.split(',')]) for s in sub_series[:-1]]  # Excluding the last empty segment\n",
    "    return sub_series_data\n",
    "\n",
    "# Read the time series data\n",
    "all_sub_time_series = []\n",
    "with open(ts_file_path, 'r') as file:\n",
    "    for _ in range(10):\n",
    "        line = file.readline()\n",
    "        sub_time_series = process_line(line)\n",
    "        all_sub_time_series.append(sub_time_series)\n",
    "\n",
    "# Load the change points and PIDs for each time series\n",
    "change_points_and_pids = np.load(npy_file_path, allow_pickle=True)[:10]\n",
    "\n",
    "# Concatenate all sub-series into a single series for each main series\n",
    "all_single_series = [np.concatenate(sub_series) for sub_series in all_sub_time_series]\n",
    "\n",
    "# Iterate over each line's single time series, their corresponding change points, and PIDs\n",
    "for i, (single_series, cp_and_pid) in enumerate(zip(all_single_series, change_points_and_pids)):\n",
    "    pid = cp_and_pid[0]  # The first element in each array is the PID\n",
    "    series_identifier = f\"{pid}\"\n",
    "\n",
    "    # Process the change points\n",
    "    true_change_points = [int(cp) for cp in cp_and_pid[1:-1] if cp.isdigit()]\n",
    "\n",
    "    # Parameters for the Binseg function\n",
    "    cost_func = \"l2\"\n",
    "    n_cps = len(true_change_points)\n",
    "    detected_cps = binseg(single_series, n_cps, cost_func)\n",
    "\n",
    "    # Evaluate the detected change points\n",
    "    try:\n",
    "        dataset, true_cps, detected_cps, f1_score, covering_score = evaluate_binseg(series_identifier, single_series, true_change_points, cost_func=cost_func)\n",
    "        print(f\"{series_identifier} - True Change Points: {true_change_points}\")\n",
    "        print(f\"{series_identifier} - Detected Change Points: {detected_cps}\")\n",
    "        print(f\"{series_identifier} - F1 Score: {f1_score}, Covering Score: {covering_score}\")\n",
    "    except TypeError as e:\n",
    "        print(f\"An error occurred for {series_identifier}: {e}\")\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(single_series, label='Time Series Data')\n",
    "    for cp in detected_cps:\n",
    "        plt.axvline(x=cp, color='red', linestyle='--', linewidth=1, label='Detected Change Point' if cp == detected_cps[0] else \"\")\n",
    "    for cp in true_change_points:\n",
    "        plt.axvline(x=cp, color='green', linestyle='-', linewidth=1, label='True Change Point' if cp == true_change_points[0] else \"\")\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'Time Series Analysis for {series_identifier} with Detected and True Change Points')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refining Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Algorithms.binseg import binseg\n",
    "from Functions.evaluate_binseg import evaluate_binseg\n",
    "\n",
    "# Load the time series data and change points\n",
    "ts_file_path = '..//Data//Physio//TEST_X.ts'\n",
    "npy_file_path = '..//Data//Physio//TEST_pid.npy'\n",
    "\n",
    "def process_line(line):\n",
    "    sub_series = line.strip().split(':')\n",
    "    sub_series_data = [np.array([float(num) for num in s.split(',')]) for s in sub_series[:-1]]\n",
    "    return sub_series_data\n",
    "\n",
    "# Load the change points and PIDs for each time series\n",
    "change_points_and_pids = np.load(npy_file_path, allow_pickle=True)\n",
    "\n",
    "# Read the time series data and match with PIDs\n",
    "all_sub_time_series_by_pid = {}\n",
    "with open(ts_file_path, 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        pid = change_points_and_pids[i][0]  # Matching PID from npy file\n",
    "        sub_time_series = process_line(line)\n",
    "        if pid not in all_sub_time_series_by_pid:\n",
    "            all_sub_time_series_by_pid[pid] = []\n",
    "        all_sub_time_series_by_pid[pid].append(sub_time_series)\n",
    "\n",
    "# Create a complete time series for each PID\n",
    "all_complete_series = {}\n",
    "for pid in all_sub_time_series_by_pid:\n",
    "    transposed_series = list(zip(*all_sub_time_series_by_pid[pid]))\n",
    "    all_complete_series[pid] = [np.concatenate(sub_series) for sub_series in transposed_series]\n",
    "\n",
    "# Process each complete time series\n",
    "for pid, complete_series in all_complete_series.items():\n",
    "    cp_and_pid = next((item for item in change_points_and_pids if np.array_equal(item[0], pid)), None)\n",
    "    if cp_and_pid is None:\n",
    "        continue\n",
    "\n",
    "    for i, single_series in enumerate(complete_series):\n",
    "        series_identifier = f\"{pid}_{i}\"\n",
    "\n",
    "        true_change_points = [int(cp) for cp in cp_and_pid[1:-1] if cp.isdigit()]\n",
    "\n",
    "        cost_func = \"l2\"\n",
    "        n_cps = len(true_change_points)\n",
    "        detected_cps = binseg(single_series, n_cps, cost_func)\n",
    "\n",
    "        try:\n",
    "            dataset, true_cps, detected_cps, f1_score, covering_score = evaluate_binseg(series_identifier, single_series, true_change_points, cost_func=cost_func)\n",
    "            print(f\"{series_identifier} - True Change Points: {true_change_points}\")\n",
    "            print(f\"{series_identifier} - Detected Change Points: {detected_cps}\")\n",
    "            print(f\"{series_identifier} - F1 Score: {f1_score}, Covering Score: {covering_score}\")\n",
    "        except TypeError as e:\n",
    "            print(f\"An error occurred for {series_identifier}: {e}\")\n",
    "\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.plot(single_series, label='Time Series Data')\n",
    "        for cp in detected_cps:\n",
    "            plt.axvline(x=cp, color='red', linestyle='--', linewidth=1, label='Detected Change Point' if cp == detected_cps[0] else \"\")\n",
    "        for cp in true_change_points:\n",
    "            plt.axvline(x=cp, color='green', linestyle='-', linewidth=1, label='True Change Point' if cp == true_change_points[0] else \"\")\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'Time Series Analysis for {series_identifier} with Detected and True Change Points')\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Algorithms.binseg import binseg\n",
    "from Functions.evaluate_binseg import evaluate_binseg\n",
    "\n",
    "# Load the time series data and change points\n",
    "ts_file_path = '..//Data//Physio//TEST_X.ts'\n",
    "npy_file_path = '..//Data//Physio//TEST_pid.npy'\n",
    "\n",
    "def process_line(line):\n",
    "    sub_series = line.strip().split(':')\n",
    "    sub_series_data = [np.array([float(num) for num in s.split(',')]) for s in sub_series[:-1]]\n",
    "    return sub_series_data\n",
    "\n",
    "# Load the change points and PIDs for each time series\n",
    "change_points_and_pids = np.load(npy_file_path, allow_pickle=True)\n",
    "\n",
    "# Read the time series data and match with PIDs\n",
    "all_sub_time_series_by_pid = {}\n",
    "with open(ts_file_path, 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        pid = change_points_and_pids[i][0]  # Matching PID from npy file\n",
    "        sub_time_series = process_line(line)\n",
    "        if pid not in all_sub_time_series_by_pid:\n",
    "            all_sub_time_series_by_pid[pid] = []\n",
    "        all_sub_time_series_by_pid[pid].append(sub_time_series)\n",
    "\n",
    "# Create a complete time series for each PID\n",
    "all_complete_series = {}\n",
    "for pid in all_sub_time_series_by_pid:\n",
    "    transposed_series = list(zip(*all_sub_time_series_by_pid[pid]))\n",
    "    all_complete_series[pid] = [np.concatenate(sub_series) for sub_series in transposed_series]\n",
    "\n",
    "# Series labels\n",
    "series_labels = [\n",
    "    'B8E3_Waist_Accel_LN_X', 'B8E3_Waist_Accel_LN_Y', 'B8E3_Waist_Accel_LN_Z',\n",
    "    'B8E3_Waist_Gyro_X', 'B8E3_Waist_Gyro_Y', 'B8E3_Waist_Gyro_Z', \n",
    "    'B8E3_Waist_Mag_X', 'B8E3_Waist_Mag_Y', 'B8E3_Waist_Mag_Z'\n",
    "]\n",
    "\n",
    "# Process each complete time series\n",
    "for pid, complete_series in all_complete_series.items():\n",
    "    # Extracting all change points for the current PID across all instances\n",
    "    all_cp_instances = [item for item in change_points_and_pids if np.array_equal(item[0], pid)]\n",
    "    true_change_points = []\n",
    "    for instance in all_cp_instances:\n",
    "        # Check if the last entry is '10' or '11', indicating two change points\n",
    "        if instance[-1] == '10' or instance[-1] == '11':\n",
    "            true_change_points.extend([int(cp) for cp in instance[1:3] if cp.isdigit()])\n",
    "        else:\n",
    "            true_change_points.append(int(instance[1]))  # Take the first number\n",
    "\n",
    "    true_change_points = sorted(list(set(true_change_points)))  # Sort and remove duplicates\n",
    "\n",
    "    for i, single_series in enumerate(complete_series):\n",
    "        series_identifier = f\"{pid}_{series_labels[i]}\"\n",
    "\n",
    "        cost_func = \"l2\"\n",
    "        n_cps = min(len(true_change_points), len(single_series) - 1)\n",
    "        detected_cps = binseg(single_series, n_cps, cost_func)\n",
    "\n",
    "        try:\n",
    "            dataset, true_cps, detected_cps, f1_score, covering_score = evaluate_binseg(series_identifier, single_series, true_change_points, cost_func=cost_func)\n",
    "            print(f\"{series_identifier} - True Change Points: {sorted(true_change_points)}\")\n",
    "            print(f\"{series_identifier} - Detected Change Points: {detected_cps}\")\n",
    "            print(f\"{series_identifier} - F1 Score: {f1_score}, Covering Score: {covering_score}\")\n",
    "        except TypeError as e:\n",
    "            print(f\"An error occurred for {series_identifier}: {e}\")\n",
    "\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.plot(single_series, label='Time Series Data')\n",
    "        for cp in detected_cps:\n",
    "            plt.axvline(x=cp, color='red', linestyle='--', linewidth=1, label='Detected Change Point' if cp == detected_cps[0] else \"\")\n",
    "        for cp in true_change_points:\n",
    "            plt.axvline(x=cp, color='green', linestyle='-', linewidth=1, label='True Change Point' if cp == true_change_points[0] else \"\")\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'Time Series Analysis for {series_identifier} with Detected and True Change Points')\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing max length of subparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Algorithms.binseg import binseg\n",
    "from Functions.evaluate_binseg import evaluate_binseg\n",
    "import time\n",
    "\n",
    "# Load the time series data and change points\n",
    "ts_file_path = '..//Data//Physio//TEST_X.ts'\n",
    "npy_file_path = '..//Data//Physio//TEST_pid.npy'\n",
    "\n",
    "def process_line(line):\n",
    "    sub_series = line.strip().split(':')\n",
    "    sub_series_data = [np.array([float(num) for num in s.split(',')]) for s in sub_series[:-1]]\n",
    "    return sub_series_data\n",
    "\n",
    "change_points_and_pids = np.load(npy_file_path, allow_pickle=True)\n",
    "\n",
    "all_sub_time_series_by_pid = {}\n",
    "with open(ts_file_path, 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        pid = change_points_and_pids[i][0]\n",
    "        sub_time_series = process_line(line)\n",
    "        if pid not in all_sub_time_series_by_pid:\n",
    "            all_sub_time_series_by_pid[pid] = []\n",
    "        all_sub_time_series_by_pid[pid].append(sub_time_series)\n",
    "\n",
    "all_complete_series = {}\n",
    "for pid in all_sub_time_series_by_pid:\n",
    "    transposed_series = list(zip(*all_sub_time_series_by_pid[pid]))\n",
    "    all_complete_series[pid] = [np.concatenate(sub_series) for sub_series in transposed_series]\n",
    "\n",
    "series_labels = [\n",
    "    'B8E3_Waist_Accel_LN_X', 'B8E3_Waist_Accel_LN_Y', 'B8E3_Waist_Accel_LN_Z',\n",
    "    'B8E3_Waist_Gyro_X', 'B8E3_Waist_Gyro_Y', 'B8E3_Waist_Gyro_Z', \n",
    "    'B8E3_Waist_Mag_X', 'B8E3_Waist_Mag_Y', 'B8E3_Waist_Mag_Z'\n",
    "]\n",
    "\n",
    "# Initialize accumulators for total time, F1 score, and coverage score\n",
    "total_time = 0\n",
    "total_f1_score = 0\n",
    "total_covering_score = 0\n",
    "series_processed = 0\n",
    "\n",
    "for pid, complete_series in all_complete_series.items():\n",
    "    all_cp_instances = [item for item in change_points_and_pids if np.array_equal(item[0], pid)]\n",
    "    true_change_points = []\n",
    "    for instance in all_cp_instances:\n",
    "        if instance[-1] == '10' or instance[-1] == '11':\n",
    "            true_change_points.extend([int(cp) for cp in instance[1:3] if cp.isdigit()])\n",
    "        else:\n",
    "            true_change_points.append(int(instance[1]))\n",
    "\n",
    "    true_change_points = sorted(list(set(true_change_points)))\n",
    "\n",
    "    for i, single_series in enumerate(complete_series):\n",
    "        series_identifier = f\"{pid}_{series_labels[i]}\"\n",
    "        cost_func = \"l2\"\n",
    "        n_cps = min(len(true_change_points), len(single_series) - 1)\n",
    "\n",
    "        start_time = time.time()\n",
    "        detected_cps = binseg(single_series, n_cps, cost_func)\n",
    "        end_time = time.time()\n",
    "\n",
    "        algorithm_duration = end_time - start_time\n",
    "        total_time += algorithm_duration\n",
    "\n",
    "        try:\n",
    "            dataset, true_cps, detected_cps, f1_score, covering_score = evaluate_binseg(series_identifier, single_series, true_change_points, cost_func=cost_func)\n",
    "            print(f\"{series_identifier} - True Change Points: {sorted(true_change_points)}\")\n",
    "            print(f\"{series_identifier} - Detected Change Points: {detected_cps}\")\n",
    "            print(f\"{series_identifier} - F1 Score: {f1_score}, Covering Score: {covering_score}\")\n",
    "            print(f\"{series_identifier} - Algorithm Duration: {algorithm_duration:.2f} seconds\")\n",
    "\n",
    "            total_f1_score += f1_score\n",
    "            total_covering_score += covering_score\n",
    "            series_processed += 1\n",
    "\n",
    "        except TypeError as e:\n",
    "            print(f\"An error occurred for {series_identifier}: {e}\")\n",
    "\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.plot(single_series, label='Time Series Data')\n",
    "        for cp in detected_cps:\n",
    "            plt.axvline(x=cp, color='red', linestyle='--', linewidth=1, label='Detected Change Point' if cp == detected_cps[0] else \"\")\n",
    "        for cp in true_change_points:\n",
    "            plt.axvline(x=cp, color='green', linestyle='-', linewidth=1, label='True Change Point' if cp == true_change_points[0] else \"\")\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'Time Series Analysis for {series_identifier} with Detected and True Change Points')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Compute the average metrics\n",
    "average_time = total_time / series_processed if series_processed > 0 else 0\n",
    "average_f1_score = total_f1_score / series_processed if series_processed > 0 else 0\n",
    "average_covering_score = total_covering_score / series_processed if series_processed > 0 else 0\n",
    "\n",
    "# Print the average metrics\n",
    "print(f\"Average Algorithm Duration: {average_time:.2f} seconds\")\n",
    "print(f\"Average F1 Score: {average_f1_score:.2f}\")\n",
    "print(f\"Average Covering Score: {average_covering_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TSFYP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
